{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 8\n",
    "sample_weights = [1/8]*num_samples\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), \"..\"))\n",
    "from tree.DecisionTree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets.load_breast_cancer()\n",
    "X,y=dataset.data,dataset.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.Node.Node at 0x1a6e55110a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = tree._build_decision_tree(X_train,y_train)\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1\n",
      "2 0 1\n",
      "29 0 1\n",
      "39 0 1\n",
      "45 0 1\n",
      "75 0 1\n",
      "81 0 1\n",
      "85 0 1\n",
      "93 0 1\n",
      "95 0 1\n",
      "107 0 1\n",
      "125 0 1\n",
      "137 0 1\n",
      "157 0 1\n",
      "201 0 1\n",
      "202 1 0\n",
      "209 0 1\n",
      "253 0 1\n",
      "263 0 1\n",
      "272 1 0\n",
      "274 0 1\n",
      "327 0 1\n",
      "360 0 1\n",
      "369 0 1\n",
      "383 0 1\n",
      "405 1 0\n",
      "407 0 1\n",
      "410 1 0\n",
      "414 0 1\n",
      "419 0 1\n",
      "427 0 1\n",
      "435 0 1\n",
      "[0, 2, 29, 39, 45, 75, 81, 85, 93, 95, 107, 125, 137, 157, 201, 202, 209, 253, 263, 272, 274, 327, 360, 369, 383, 405, 407, 410, 414, 419, 427, 435]\n"
     ]
    }
   ],
   "source": [
    "misclassified_idxs = []\n",
    "idx = 0\n",
    "for x,y in zip(X_train,y_train):\n",
    "    ans = tree._traverse_decision_tree(x,node)\n",
    "    if ans!=y:\n",
    "        print(idx,ans,y)\n",
    "        misclassified_idxs.append(idx)\n",
    "        idx+=1\n",
    "    else:\n",
    "        idx+=1\n",
    "print(misclassified_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misclassified_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = 1 / len(X_train)\n",
    "sample_weights = [sample_weight]*len(X_train)\n",
    "sample_weights = np.array(sample_weights)\n",
    "total_error = np.sum(sample_weights[misclassified_idxs])\n",
    "ratio = (1 - total_error) / total_error\n",
    "performance_of_stump = 0.5 * np.log(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2908181381232757"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_of_stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isin(np.arange(0,len(X_train)),misclassified_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0021978, 0.0006045, 0.0021978, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0021978, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0021978, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0021978, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0021978, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0021978, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0021978, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0021978, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0021978,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0021978, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0021978, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045,\n",
       "       0.0006045, 0.0006045, 0.0006045, 0.0006045, 0.0006045])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights[mask]*np.exp(performance_of_stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHAITA~1\\AppData\\Local\\Temp/ipykernel_11220/1913544766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#sample_weights[~mask]*np.exp(-performance_of_stump)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mperformance_of_stump\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperformance_of_stump\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# correctly_classified_samples = X_train[~mask]\n",
    "# misclassified_samples = X_train[mask]\n",
    "#sample_weights[~mask]*np.exp(-performance_of_stump)\n",
    "sample_weights[~mask] *= np.exp(-performance_of_stump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights[mask] *= np.exp(performance_of_stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights /= np.sum(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins =  np.cumsum(sample_weights)\n",
    "bins = np.insert(bins,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35364572904891045"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_num = np.random.random_sample()\n",
    "random_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.015625  , 0.01680703, 0.03243203, 0.03361407,\n",
       "       0.0347961 , 0.03597813, 0.03716017, 0.0383422 , 0.03952423,\n",
       "       0.04070626, 0.0418883 , 0.04307033, 0.04425236, 0.0454344 ,\n",
       "       0.04661643, 0.04779846, 0.0489805 , 0.05016253, 0.05134456,\n",
       "       0.0525266 , 0.05370863, 0.05489066, 0.0560727 , 0.05725473,\n",
       "       0.05843676, 0.05961879, 0.06080083, 0.06198286, 0.06316489,\n",
       "       0.07878989, 0.07997193, 0.08115396, 0.08233599, 0.08351803,\n",
       "       0.08470006, 0.08588209, 0.08706413, 0.08824616, 0.08942819,\n",
       "       0.10505319, 0.10623522, 0.10741726, 0.10859929, 0.10978132,\n",
       "       0.11096336, 0.12658836, 0.12777039, 0.12895242, 0.13013446,\n",
       "       0.13131649, 0.13249852, 0.13368056, 0.13486259, 0.13604462,\n",
       "       0.13722665, 0.13840869, 0.13959072, 0.14077275, 0.14195479,\n",
       "       0.14313682, 0.14431885, 0.14550089, 0.14668292, 0.14786495,\n",
       "       0.14904699, 0.15022902, 0.15141105, 0.15259309, 0.15377512,\n",
       "       0.15495715, 0.15613918, 0.15732122, 0.15850325, 0.15968528,\n",
       "       0.16086732, 0.17649232, 0.17767435, 0.17885638, 0.18003842,\n",
       "       0.18122045, 0.18240248, 0.19802748, 0.19920952, 0.20039155,\n",
       "       0.20157358, 0.21719858, 0.21838061, 0.21956265, 0.22074468,\n",
       "       0.22192671, 0.22310875, 0.22429078, 0.22547281, 0.24109781,\n",
       "       0.24227985, 0.25790485, 0.25908688, 0.26026891, 0.26145095,\n",
       "       0.26263298, 0.26381501, 0.26499704, 0.26617908, 0.26736111,\n",
       "       0.26854314, 0.26972518, 0.27090721, 0.28653221, 0.28771424,\n",
       "       0.28889628, 0.29007831, 0.29126034, 0.29244238, 0.29362441,\n",
       "       0.29480644, 0.29598848, 0.29717051, 0.29835254, 0.29953457,\n",
       "       0.30071661, 0.30189864, 0.30308067, 0.30426271, 0.30544474,\n",
       "       0.30662677, 0.32225177, 0.32343381, 0.32461584, 0.32579787,\n",
       "       0.32697991, 0.32816194, 0.32934397, 0.330526  , 0.33170804,\n",
       "       0.33289007, 0.3340721 , 0.33525414, 0.35087914, 0.35206117,\n",
       "       0.3532432 , 0.35442524, 0.35560727, 0.3567893 , 0.35797134,\n",
       "       0.35915337, 0.3603354 , 0.36151743, 0.36269947, 0.3638815 ,\n",
       "       0.36506353, 0.36624557, 0.3674276 , 0.36860963, 0.36979167,\n",
       "       0.3709737 , 0.37215573, 0.37333777, 0.38896277, 0.3901448 ,\n",
       "       0.39132683, 0.39250887, 0.3936909 , 0.39487293, 0.39605496,\n",
       "       0.397237  , 0.39841903, 0.39960106, 0.4007831 , 0.40196513,\n",
       "       0.40314716, 0.4043292 , 0.40551123, 0.40669326, 0.4078753 ,\n",
       "       0.40905733, 0.41023936, 0.41142139, 0.41260343, 0.41378546,\n",
       "       0.41496749, 0.41614953, 0.41733156, 0.41851359, 0.41969563,\n",
       "       0.42087766, 0.42205969, 0.42324173, 0.42442376, 0.42560579,\n",
       "       0.42678783, 0.42796986, 0.42915189, 0.43033392, 0.43151596,\n",
       "       0.43269799, 0.43388002, 0.43506206, 0.43624409, 0.43742612,\n",
       "       0.43860816, 0.43979019, 0.45541519, 0.47104019, 0.47222222,\n",
       "       0.47340426, 0.47458629, 0.47576832, 0.47695035, 0.47813239,\n",
       "       0.49375739, 0.49493942, 0.49612145, 0.49730349, 0.49848552,\n",
       "       0.49966755, 0.50084959, 0.50203162, 0.50321365, 0.50439569,\n",
       "       0.50557772, 0.50675975, 0.50794178, 0.50912382, 0.51030585,\n",
       "       0.51148788, 0.51266992, 0.51385195, 0.51503398, 0.51621602,\n",
       "       0.51739805, 0.51858008, 0.51976212, 0.52094415, 0.52212618,\n",
       "       0.52330822, 0.52449025, 0.52567228, 0.52685431, 0.52803635,\n",
       "       0.52921838, 0.53040041, 0.53158245, 0.53276448, 0.53394651,\n",
       "       0.53512855, 0.53631058, 0.53749261, 0.53867465, 0.53985668,\n",
       "       0.54103871, 0.54222074, 0.54340278, 0.54458481, 0.56020981,\n",
       "       0.56139184, 0.56257388, 0.56375591, 0.56493794, 0.56611998,\n",
       "       0.56730201, 0.56848404, 0.56966608, 0.57084811, 0.58647311,\n",
       "       0.58765514, 0.58883717, 0.59001921, 0.59120124, 0.59238327,\n",
       "       0.59356531, 0.59474734, 0.59592937, 0.61155437, 0.61273641,\n",
       "       0.62836141, 0.62954344, 0.63072547, 0.63190751, 0.63308954,\n",
       "       0.63427157, 0.63545361, 0.63663564, 0.63781767, 0.6389997 ,\n",
       "       0.64018174, 0.64136377, 0.6425458 , 0.64372784, 0.64490987,\n",
       "       0.6460919 , 0.64727394, 0.64845597, 0.649638  , 0.65082004,\n",
       "       0.65200207, 0.6531841 , 0.65436613, 0.65554817, 0.6567302 ,\n",
       "       0.65791223, 0.65909427, 0.6602763 , 0.66145833, 0.66264037,\n",
       "       0.6638224 , 0.66500443, 0.66618647, 0.6673685 , 0.66855053,\n",
       "       0.66973257, 0.6709146 , 0.67209663, 0.67327866, 0.6744607 ,\n",
       "       0.67564273, 0.67682476, 0.6780068 , 0.67918883, 0.68037086,\n",
       "       0.6815529 , 0.68273493, 0.68391696, 0.685099  , 0.68628103,\n",
       "       0.68746306, 0.68864509, 0.68982713, 0.70545213, 0.70663416,\n",
       "       0.70781619, 0.70899823, 0.71018026, 0.71136229, 0.71254433,\n",
       "       0.71372636, 0.71490839, 0.71609043, 0.71727246, 0.71845449,\n",
       "       0.71963652, 0.72081856, 0.72200059, 0.72318262, 0.72436466,\n",
       "       0.72554669, 0.72672872, 0.72791076, 0.72909279, 0.73027482,\n",
       "       0.73145686, 0.73263889, 0.73382092, 0.73500296, 0.73618499,\n",
       "       0.73736702, 0.73854905, 0.73973109, 0.74091312, 0.74209515,\n",
       "       0.74327719, 0.75890219, 0.76008422, 0.76126625, 0.76244829,\n",
       "       0.76363032, 0.76481235, 0.76599439, 0.76717642, 0.76835845,\n",
       "       0.78398345, 0.78516548, 0.78634752, 0.78752955, 0.78871158,\n",
       "       0.78989362, 0.79107565, 0.79225768, 0.79343972, 0.79462175,\n",
       "       0.79580378, 0.79698582, 0.79816785, 0.79934988, 0.81497488,\n",
       "       0.81615691, 0.81733895, 0.81852098, 0.81970301, 0.82088505,\n",
       "       0.82206708, 0.82324911, 0.82443115, 0.82561318, 0.82679521,\n",
       "       0.82797725, 0.82915928, 0.83034131, 0.83152335, 0.83270538,\n",
       "       0.83388741, 0.83506944, 0.83625148, 0.83743351, 0.83861554,\n",
       "       0.83979758, 0.85542258, 0.85660461, 0.87222961, 0.87341164,\n",
       "       0.87459368, 0.89021868, 0.89140071, 0.89258274, 0.89376478,\n",
       "       0.90938978, 0.91057181, 0.91175384, 0.91293587, 0.91411791,\n",
       "       0.92974291, 0.93092494, 0.93210697, 0.93328901, 0.93447104,\n",
       "       0.93565307, 0.93683511, 0.93801714, 0.95364214, 0.95482417,\n",
       "       0.95600621, 0.95718824, 0.95837027, 0.9595523 , 0.96073434,\n",
       "       0.96191637, 0.97754137, 0.9787234 , 0.97990544, 0.98108747,\n",
       "       0.9822695 , 0.98345154, 0.98463357, 0.9858156 , 0.98699764,\n",
       "       0.98817967, 0.9893617 , 0.99054374, 0.99172577, 0.9929078 ,\n",
       "       0.99408983, 0.99527187, 0.9964539 , 0.99763593, 0.99881797,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(0.9991,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.72,\n",
       " 13.78,\n",
       " 81.78,\n",
       " 492.1,\n",
       " 0.09667,\n",
       " 0.08393,\n",
       " 0.01288,\n",
       " 0.01924,\n",
       " 0.1638,\n",
       " 0.061,\n",
       " 0.1807,\n",
       " 0.6931,\n",
       " 1.34,\n",
       " 13.38,\n",
       " 0.006064,\n",
       " 0.0118,\n",
       " 0.006564,\n",
       " 0.007978,\n",
       " 0.01374,\n",
       " 0.001392,\n",
       " 13.5,\n",
       " 17.48,\n",
       " 88.54,\n",
       " 553.7,\n",
       " 0.1298,\n",
       " 0.1472,\n",
       " 0.05233,\n",
       " 0.06343,\n",
       " 0.2369,\n",
       " 0.06922]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train[454])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_num > bins[139] and random_num < bins[140]:\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = []\n",
    "new_y_train = []\n",
    "\n",
    "for _ in range(len(X_train)):\n",
    "    random_num = np.random.random_sample()\n",
    "    idx = np.digitize(random_num,bins) - 1\n",
    "    X_data = list(X_train[idx])\n",
    "    y_data = y_train[idx]\n",
    "    new_X_train.append(X_data)\n",
    "    new_y_train.append(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_X_train = np.array(new_X_train)\n",
    "updated_y_train = np.array(new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=datasets.load_breast_cancer()\n",
    "X,y=dataset.data,dataset.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 0]\n",
      "[1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 0]\n",
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "ad = AdaBoostClassifier(n_estimators=10)\n",
    "ad.fit(X_train,y_train)\n",
    "res = ad.predict(X_test)\n",
    "print(res)\n",
    "print(y_test)\n",
    "acc=np.sum(res==y_test)/len(y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHAITA~1\\AppData\\Local\\Temp/ipykernel_6376/3039480066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "np.log(1/0) + 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "802e9de2995c34f5c91d5c52c8734bc980978f09835a5c222977adcbf3cb2092"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
